{
  "metrics": {
    "pass@1": 0.0,
    "edit_similarity": 0.19775023263432312,
    "exact_match": 0.0,
    "balanced_score": 0.09416677744491576,
    "total_samples": 50,
    "passes": 0,
    "temperature": 0.4,
    "max_tokens": 192
  },
  "results": [
    {
      "index": 0,
      "groundtruth": "sequence_actual[:, -max_stop_string:])[0]",
      "prediction": "old_tail = tokenizer.decode(generator.",
      "es": 0.07317073170731703,
      "em": false,
      "passed": false
    },
    {
      "index": 1,
      "groundtruth": "gen_accept_token(batch_token)",
      "prediction": "We need to fill the missing code in the generate_cfg",
      "es": 0.13461538461538458,
      "em": false,
      "passed": false
    },
    {
      "index": 2,
      "groundtruth": "settings.token_repetition_penalty_max = 1.176",
      "prediction": "generator.",
      "es": 0.15555555555555556,
      "em": false,
      "passed": false
    },
    {
      "index": 3,
      "groundtruth": "decode(prompt_ids)[0]",
      "prediction": "full_prompt = prompt",
      "es": 0.23809523809523814,
      "em": false,
      "passed": false
    },
    {
      "index": 4,
      "groundtruth": "gen_begin_reuse(input_ids)",
      "prediction": "generator.settings = gen_settings",
      "es": 0.24242424242424243,
      "em": false,
      "passed": false
    },
    {
      "index": 5,
      "groundtruth": "encode(prompts, return_mask = True)",
      "prediction": "def generate_cfg(prompts, alpha, max_new_tokens):",
      "es": 0.34693877551020413,
      "em": false,
      "passed": false
    },
    {
      "index": 6,
      "groundtruth": "decode(generator.sequence[0])",
      "prediction": "We need to fill missing code after \"output = tokeniz",
      "es": 0.15384615384615385,
      "em": false,
      "passed": false
    },
    {
      "index": 7,
      "groundtruth": "calculate_rotary_embedding_base()",
      "prediction": "config.alpha_value = args.alpha",
      "es": 0.1515151515151515,
      "em": false,
      "passed": false
    },
    {
      "index": 8,
      "groundtruth": "generate_simple(prompts, max_new_tokens = 200)",
      "prediction": "We need to fill missing code: generator.??. We want to generate for each prompt? T",
      "es": 0.20731707317073167,
      "em": false,
      "passed": false
    },
    {
      "index": 9,
      "groundtruth": "set_auto_map(args.gpu_split)",
      "prediction": "config.compress_pos_emb = args.compress_pos_emb",
      "es": 0.23404255319148937,
      "em": false,
      "passed": false
    },
    {
      "index": 10,
      "groundtruth": "forward(generator.sequence[:, -1:], cache, input_mask = mask)",
      "prediction": "logits = model.forward(input_ids, position_ids, attention_mask, ...)",
      "es": 0.22058823529411764,
      "em": false,
      "passed": false
    },
    {
      "index": 11,
      "groundtruth": "enter(\"b\") == ConfigRoute(\"a.b\")",
      "prediction": "def test_enter():",
      "es": 0.125,
      "em": false,
      "passed": false
    },
    {
      "index": 12,
      "groundtruth": "dispatch(cls) is export_model_async:",
      "prediction": "export_model.register(cls, func)",
      "es": 0.16666666666666663,
      "em": false,
      "passed": false
    },
    {
      "index": 13,
      "groundtruth": "compile(to_compile=to_compile)",
      "prediction": "We need to fill missing code for compile command. Let'",
      "es": 0.2592592592592593,
      "em": false,
      "passed": false
    },
    {
      "index": 14,
      "groundtruth": "set_auto_map('17.615,18.8897')",
      "prediction": "config = ExLlamaConfig(model_config_path)",
      "es": 0.09756097560975607,
      "em": false,
      "passed": false
    },
    {
      "index": 15,
      "groundtruth": "sample_current(logits_mixed)",
      "prediction": "sampled_token, _ = generator.",
      "es": 0.27586206896551724,
      "em": false,
      "passed": false
    },
    {
      "index": 16,
      "groundtruth": "sequence[:, -1:], cache, input_mask = mask)",
      "prediction": "for _ in range(max_new_tokens):",
      "es": 0.13953488372093026,
      "em": false,
      "passed": false
    },
    {
      "index": 17,
      "groundtruth": "dump(opt, f, indent=\"\\t\")",
      "prediction": "with open(opt['output_dir'] + '/option.json',",
      "es": 0.15555555555555556,
      "em": false,
      "passed": false
    },
    {
      "index": 18,
      "groundtruth": "gen_begin(ids)",
      "prediction": "print(past, end = \"\")",
      "es": 0.1428571428571429,
      "em": false,
      "passed": false
    },
    {
      "index": 19,
      "groundtruth": "load(f, object_pairs_hook=OrderedDict)  # noqa",
      "prediction": "def parse(json_path: str) -> dict:",
      "es": 0.19565217391304346,
      "em": false,
      "passed": false
    },
    {
      "index": 20,
      "groundtruth": "update(config.sources[\"default\"])",
      "prediction": "final_options = Options()",
      "es": 0.18181818181818177,
      "em": false,
      "passed": false
    },
    {
      "index": 21,
      "groundtruth": "active is False",
      "prediction": "def test_client_agent_inact",
      "es": 0.11111111111111116,
      "em": false,
      "passed": false
    },
    {
      "index": 22,
      "groundtruth": "options.keys())",
      "prediction": "assert list(config.sources[",
      "es": 0.18518518518518523,
      "em": false,
      "passed": false
    },
    {
      "index": 23,
      "groundtruth": "_logger.getEffectiveLevel() == INFO",
      "prediction": "def test_logger_default_level():",
      "es": 0.22857142857142854,
      "em": false,
      "passed": false
    },
    {
      "index": 24,
      "groundtruth": "init_parser(subparser)",
      "prediction": "We need to fill missing code in _regist",
      "es": 0.1282051282051282,
      "em": false,
      "passed": false
    },
    {
      "index": 25,
      "groundtruth": "option(\"active\"):",
      "prediction": "self._logger.info(\"AppSignal n",
      "es": 0.16666666666666663,
      "em": false,
      "passed": false
    },
    {
      "index": 26,
      "groundtruth": "gen_feed_tokens(in_tokens)",
      "prediction": "# Feed in the user input and \"{bot_name}:\", to",
      "es": 0.17391304347826086,
      "em": false,
      "passed": false
    },
    {
      "index": 27,
      "groundtruth": "gen_prune_to(config.max_seq_len - expect_tokens - extra_prune, tokenizer.newline_token_id)",
      "prediction": "if generator.gen_num_tokens() >= max_tokens:",
      "es": 0.24444444444444446,
      "em": false,
      "passed": false
    },
    {
      "index": 28,
      "groundtruth": "gen_num_tokens() >= max_tokens:",
      "prediction": "# If we're approaching the context limit, prune some wh",
      "es": 0.1454545454545455,
      "em": false,
      "passed": false
    },
    {
      "index": 29,
      "groundtruth": "disallow_tokens([tokenizer.newline_token_id, tokenizer.eos_token_id])",
      "prediction": "We need to fill missing code: inside the for loop, after if i < min_response_tokens: generator.```. So we need to call some",
      "es": 0.2195121951219512,
      "em": false,
      "passed": false
    },
    {
      "index": 30,
      "groundtruth": "decode(generator.sequence_actual[:, -num_res_tokens:][0])",
      "prediction": "We need to fill the missing code where placeholder is `text = tokenizer.```. We need to decode the cur",
      "es": 0.17647058823529416,
      "em": false,
      "passed": false
    },
    {
      "index": 31,
      "groundtruth": "sequence_actual[:, -num_res_tokens:][0])",
      "prediction": "We need to fill missing code line: `text = tokenizer.decode(generator.`",
      "es": 0.15492957746478875,
      "em": false,
      "passed": false
    },
    {
      "index": 32,
      "groundtruth": "api_populate()",
      "prediction": "We need to fill missing c",
      "es": 0.07999999999999996,
      "em": false,
      "passed": false
    },
    {
      "index": 33,
      "groundtruth": "respond_multi(user_input)), mimetype = 'application/json')",
      "prediction": "@app.route(\"/api/userinput\", methods=['POST'])",
      "es": 0.2931034482758621,
      "em": false,
      "passed": false
    },
    {
      "index": 34,
      "groundtruth": "print_options(args)",
      "prediction": "We need to fill missing code betwe",
      "es": 0.1470588235294118,
      "em": false,
      "passed": false
    },
    {
      "index": 35,
      "groundtruth": "get_delivery(data)",
      "prediction": "We need to fill missing code: af",
      "es": 0.1875,
      "em": false,
      "passed": false
    },
    {
      "index": 36,
      "groundtruth": "run()",
      "prediction": "We need t",
      "es": 0.11111111111111116,
      "em": false,
      "passed": false
    },
    {
      "index": 37,
      "groundtruth": "load_from_checkpoint(CKPT_PATH)",
      "prediction": "We need to fill missing code: instantiate model. The co",
      "es": 0.1454545454545455,
      "em": false,
      "passed": false
    },
    {
      "index": 38,
      "groundtruth": "cointerleave(n)",
      "prediction": "a = FiniteFunction.interlea",
      "es": 0.18518518518518523,
      "em": false,
      "passed": false
    },
    {
      "index": 39,
      "groundtruth": "interleave(n)",
      "prediction": "# interleave and its in",
      "es": 0.4782608695652174,
      "em": false,
      "passed": false
    },
    {
      "index": 40,
      "groundtruth": "build_req()",
      "prediction": "# Builds a request",
      "es": 0.38888888888888884,
      "em": false,
      "passed": false
    },
    {
      "index": 41,
      "groundtruth": "agg_diff_fe_calc(self.detect_data, self.anomaly_duration)",
      "prediction": "We need to fill in the missing code at `agg_list = Utils.```. We need to guess what method of Utils to",
      "es": 0.16666666666666663,
      "em": false,
      "passed": false
    },
    {
      "index": 42,
      "groundtruth": "diff_percentile_func(self.detect_data, int(k), is_down)[-1]",
      "prediction": "We need to fill the missing code: within run(), inside the for loop: \"cur_fe = Utils.\" and then something.",
      "es": 0.16981132075471694,
      "em": false,
      "passed": false
    },
    {
      "index": 43,
      "groundtruth": "diff_feature_calc(detect_data, self.default_point)",
      "prediction": "We need to fill missing code: in prev_diff_outlier, after detect_data_diff = Utils(). ...",
      "es": 0.2134831460674157,
      "em": false,
      "passed": false
    },
    {
      "index": 44,
      "groundtruth": "turkey_box_plot(detect_data_diff, self.tk_delta)[3]",
      "prediction": "We need to fill missing code: in prev_diff_outlier, after detect_data_diff = Utils().diff_f",
      "es": 0.23076923076923073,
      "em": false,
      "passed": false
    },
    {
      "index": 45,
      "groundtruth": "turkey_box_plot([freq[k] for k in search_range])[4]",
      "prediction": "We need to fill the rest. Let's inspect context: They want to compute up_threshold maybe us",
      "es": 0.1648351648351648,
      "em": false,
      "passed": false
    },
    {
      "index": 46,
      "groundtruth": "exceptions.TDMRepNoParam, self.rule.is_allowed, None, None)",
      "prediction": "self.assertRaises(dd.",
      "es": 0.15254237288135597,
      "em": false,
      "passed": false
    },
    {
      "index": 47,
      "groundtruth": "get_header_value(headers, self.HEADER_NAME)",
      "prediction": "We need to fill missing code in XRobotsTagHeader.is_allowed: inside if header",
      "es": 0.1428571428571429,
      "em": false,
      "passed": false
    },
    {
      "index": 48,
      "groundtruth": "get_header_value_from_response(response, self.HEADER_NAME)",
      "prediction": "header_value = self.get_header_value_from_response(response, self.HEADER_NAME)",
      "es": 0.7435897435897436,
      "em": false,
      "passed": false
    },
    {
      "index": 49,
      "groundtruth": "HEADER_NAME), \"noai\")",
      "prediction": "self.assertEqual(self.rule.get_header",
      "es": 0.05405405405405406,
      "em": false,
      "passed": false
    }
  ]
}